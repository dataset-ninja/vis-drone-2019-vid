**VisDrone-VID dataset** is a dataset for an object detection task. It is used in the search and rescue (SAR) industry. 

The dataset consists of 40015 images with 1870277 labeled objects belonging to 12 different classes including *pedestrian*, *car*, *ignored region*, and other: *person*, *motor*, *van*, *bicycle*, *tricycle*, *truck*, *awning tricycle*, *bus*, and *other*.

Images in the VisDrone-VID dataset have bounding box annotations. There are 3 (0% of the total) unlabeled images (i.e. without annotations). There are 3 splits in the dataset: *train* (24201 images), *test* (12968 images), and *val* (2846 images). Alternatively, the dataset could be split into 3 occlusions: ***no occlusion*** (1039744 objects), ***partial occlusion*** (713376 objects), and ***heavy occlusion*** (117157 objects), or into 2 truncations: ***no occlusion*** (1039744 objects) and ***partial occlusion*** (713376 objects). Additionally, every image marked with ***sequence*** and ***target id*** tags, test images marked with ***challenge*** or ***dev*** tag. The dataset was released in 2021 by the <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">Tianjin University, China</span>, <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">Finance America Corporation, USA</span>, <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">University at Albany, USA</span>, <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">GE Global Research, USA</span>, <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">University of North Texas, USA</span>, and <span style="font-weight: 600; color: grey; border-bottom: 1px dashed #d3d3d3;">Stony Brook University, USA</span>.

<img src="https://github.com/dataset-ninja/vis-drone-vid/raw/main/visualizations/poster.png">
